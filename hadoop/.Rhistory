q=seq(0,100,by=1);
a=10;
tc=q*2;
tc
q=seq(0,100,by=1);
a=10;
alpha=2;
beta=4;
tc=(q/a)^(1/(alpha+beta))*((alpha/beta)^(beta/(alpha+beta))+(beta/alpha)^(alpha/(alpha+beta)));
plot(tc);
plot(q,tc);
ac=tc/q;
mc=ac/(alpha+beta);
plot(q,ac);
plot(q,ac);
points(q,mc);
plot(q,pch=19,ac);
points(q,mc);
plot(q,pch=19,tc);
plot(q,pch=19,ac);
points(q,mc);
alpha=0.25;
beta=0.75;
tc=(q/a)^(1/(alpha+beta))*((alpha/beta)^(beta/(alpha+beta))+(beta/alpha)^(alpha/(alpha+beta)));
ac=tc/q;
mc=ac/(alpha+beta);
plot(q,pch=19,tc);
plot(q,pch=19,ac);
points(q,mc);
alpha=0.25;
beta=0.5;
tc=(q/a)^(1/(alpha+beta))*((alpha/beta)^(beta/(alpha+beta))+(beta/alpha)^(alpha/(alpha+beta)));
ac=tc/q;
mc=ac/(alpha+beta);
plot(q,pch=19,tc);
plot(q,pch=19,ac);
points(q,mc);
plot(q,mc);
points(q,ac,pch=19);
x=(q/10)*(1/3)^0.75;
z=(q/10)*3^0.25;
plot(x,z);
q=seq(0,100,by=10);
x=(q/10)*(1/3)^0.75;
z=(q/10)*3^0.25;
plot(x,z);
x1=seq(0,4,by=0.1);
z1=(10/10/x1^0.25)^(1/0.75);
lines(x1,z1);
z2=(20/10/x1^0.25)^(1/0.75);
lines(x1,z2);
z3=(30/10/x1^0.25)^(1/0.75);
lines(x1,z3);
z4=(40/10/x1^0.25)^(1/0.75);
lines(x1,z4);
z1=(50/10/x1^0.25)^(1/0.75);
lines(x1,z1);
z2=(60/10/x1^0.25)^(1/0.75);
lines(x1,z2);
z3=(70/10/x1^0.25)^(1/0.75);
lines(x1,z3);
z4=(80/10/x1^0.25)^(1/0.75);
lines(x1,z4);
lines(x1,z4);
lines(x1,z4);
z3=(90/10/x1^0.25)^(1/0.75);
lines(x1,z3);
z4=(100/10/x1^0.25)^(1/0.75);
lines(x1,z4);
x1=seq(0,5,by=0.1);
z1=(10/10/x1^0.25)^(1/0.75);
lines(x1,z1);
z2=(20/10/x1^0.25)^(1/0.75);
lines(x1,z2);
z3=(30/10/x1^0.25)^(1/0.75);
lines(x1,z3);
z4=(40/10/x1^0.25)^(1/0.75);
lines(x1,z4);
z1=(50/10/x1^0.25)^(1/0.75);
lines(x1,z1);
z2=(60/10/x1^0.25)^(1/0.75);
lines(x1,z2);
z3=(70/10/x1^0.25)^(1/0.75);
lines(x1,z3);
z4=(80/10/x1^0.25)^(1/0.75);
lines(x1,z4);
z3=(90/10/x1^0.25)^(1/0.75);
lines(x1,z3);
z4=(100/10/x1^0.25)^(1/0.75);
lines(x1,z4);
plot(x,z,pch=19);
lines(x,z);
x1=seq(0,5,by=0.1);
z1=(10/10/x1^0.25)^(1/0.75);
lines(x1,z1);
z2=(20/10/x1^0.25)^(1/0.75);
lines(x1,z2);
z3=(30/10/x1^0.25)^(1/0.75);
lines(x1,z3);
z4=(40/10/x1^0.25)^(1/0.75);
lines(x1,z4);
z1=(50/10/x1^0.25)^(1/0.75);
lines(x1,z1);
z2=(60/10/x1^0.25)^(1/0.75);
lines(x1,z2);
z3=(70/10/x1^0.25)^(1/0.75);
lines(x1,z3);
z4=(80/10/x1^0.25)^(1/0.75);
lines(x1,z4);
z3=(90/10/x1^0.25)^(1/0.75);
lines(x1,z3);
z4=(100/10/x1^0.25)^(1/0.75);
lines(x1,z4);
36^0.75
16^0.75
(2.5*80^4)^(1/3)
Sys.info()
time
session.info()
sessionInfo()
system('cd download',intern=false)
system('cd download',intern=FALSE)
install.packages("RPostgreSQL")
library(RPostgreSQL)
install.packages("RPostgreSQL")
library(RPostgreSQL)
drv <- dbDriver("PostgreSQL")
con <- dbConnect(drv, dbname="tempdb")
con <- dbConnect(drv, dbname="test")
install.packages("RMySQL")
library("RMySQL", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
con2 <- dbConnect(MySQL(),dbname="test")
load("~/courses/STA250/STA250_HW1/results3.rda")
fix(`M3Info`)
fix(`M3Info`)
install.packages("twitteR")
install.packages("plyr")
library(twitteR)
library(plyr)
reqURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "http://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
consumerKey <- "If4vq0alW7NO0DpU7rgOuA"
consumerSecret <- "Qu7KL9XNtgXfAsNx6qyxwUZxCmN8RQAWrLTVkNF8FU"
twitCred <- OAuthFactory$new(consumerKey=consumerKey,consumerSecret=consumerSecret,requestURL=reqURL,accessURL=accessURL,authURL=authURL)
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
twitCred$handshake(cainfo="cacert.pem")
twitCred$handshake(cainfo="cacert.pem")
setwd("~/courses/STA250/STA250HW2/hadoop")
uniq <- read.csv("output.txt", header = FALSE, sep = "")
View(uniq)
uniq
nrow(uniq)
uniq[-norw(uniq),]
uniq[-nrow(uniq),]
n = sum(uniq[,2])
uniq
uniq <- uniq[-nrow(uniq),]
n = sum(uniq[,2])
uniq <- read.csv("output.txt", header = FALSE, sep = "")
# Remove last row (NA)
row = nrow(uniq)
uniq <- uniq[-row,]
row <- row-1
# Data size
n = sum(uniq[,2])
attach(uniq)
uniq <- uniq[order(),]
View(uniq)
uniq <- read.csv("output.txt", header = FALSE, sep = "")
View(uniq)
attach(uniq)
uniq <- uniq[order(V1),]
View(uniq)
detach(uniq)
View(uniq)
# Remove last row (NA)
row = nrow(uniq)
uniq <- uniq[-row,]
row <- row-1
n = sum(uniq[,3])
uniq <- read.csv("output.txt", header = FALSE, sep = "")
attach(uniq)
uniq <- uniq[order(V1),]
detach(uniq)
# Remove last row (NA)
row = nrow(uniq)
uniq <- uniq[-row,-1]
row <- row-1
uniq
uniq <- read.csv("output.txt", header = FALSE, sep = "")
attach(uniq)
uniq <- uniq[order(V1),]
detach(uniq)
View(uniq)
uniq <- uniq[,-1]
uniq <- read.csv("output.txt", header = FALSE, sep = "")
attach(uniq)
uniq <- uniq[order(V1),]
detach(uniq)
# Remove last row (NA)
row = nrow(uniq)
uniq <- uniq[-row,]
row <- row-1
# Data size
n = sum(uniq[,2])
SumDelay = 0
for (i in 1:row){
SumDelay =  SumDelay + uniq[i,2] * uniq[i,3]
}
Mean = SumDelay/n
fix(Mean)
Mean
uniq[2,3]
uniq[1,2]
uniq[1,1]
uniq
View(uniq)
uniq[1:100,]
n = sum(uniq[,2])
# Calculate average
SumDelay = 0
for (i in 1:row){
SumDelay =  SumDelay + uniq[i,1] * uniq[i,2]
}
Mean = SumDelay/n
# Calculate standard variation
Var = 0
for (i in 1:row){
Var = Var + (uniq[i,2] - Mean)^2 * uniq[i,1]
}
SD = sqrt(Var/n)
# Calculate standard variation
Var = 0
for (i in 1:row){
Var = Var + (uniq[i,1] - Mean)^2 * uniq[i,2]
}
SD = sqrt(Var/n)
# Find the median, the average of values of index mid1 and mid2
if(n%%2 == 0){
mid1 = n/2
mid2 = mid1 + 1
}
if(n%%2 == 1){
mid1 = n/2 + 0.5
mid2 = mid1
}
# Use t1, t2 to track current index
t1 = 0
t2 = uniq[1,2]
for (i in 1:(row-1)){
if(t1 < mid1 && t2 >= mid1)
m1 = uniq[i,1]
if(t1 < mid2 && t2 >= mid2){
m2 = uniq[i,1]
break
}
t1 = t2
t2 = t2 + uniq[i+1,2]
}
Median = (m1 + m2)/2
# Read the output file(frequency table) from Hadoop and calculate the mean, sd and median
# Timer starts here
start <- proc.time()
uniq <- read.csv("output.txt", header = FALSE, sep = "")
attach(uniq)
uniq <- uniq[order(V1),]
detach(uniq)
# Remove last row (NA)
row = nrow(uniq)
uniq <- uniq[-row,]
row <- row-1
# Data size
n = sum(uniq[,2])
# Calculate average
SumDelay = 0
for (i in 1:row){
SumDelay =  SumDelay + uniq[i,1] * uniq[i,2]
}
Mean = SumDelay/n
# Calculate standard variation
Var = 0
for (i in 1:row){
Var = Var + (uniq[i,1] - Mean)^2 * uniq[i,2]
}
SD = sqrt(Var/n)
# Find the median, the average of values of index mid1 and mid2
if(n%%2 == 0){
mid1 = n/2
mid2 = mid1 + 1
}
if(n%%2 == 1){
mid1 = n/2 + 0.5
mid2 = mid1
}
# Use t1, t2 to track current index
t1 = 0
t2 = uniq[1,2]
for (i in 1:(row-1)){
if(t1 < mid1 && t2 >= mid1)
m1 = uniq[i,1]
if(t1 < mid2 && t2 >= mid2){
m2 = uniq[i,1]
break
}
t1 = t2
t2 = t2 + uniq[i+1,2]
}
Median = (m1 + m2)/2
# Timer stops here
time = proc.time()-start
# Result: Mean = 6.5665 SD = 31.5563 Median = 0 time = 0.437s
time
